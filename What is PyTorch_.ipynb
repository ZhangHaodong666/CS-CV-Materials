{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"What is PyTorch_.ipynb","provenance":[{"file_id":"1_9UkVVTHfpP0xgGB01Pppo_F82leoqTX","timestamp":1591015008515}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"QDa6ekhTpKS0","colab_type":"text"},"source":["# What is PyTorch?\n","\n","このノートブックでは，近年において最も主流な深層学習フレームワークのひとつであるPyTorchについて基本的な事項を説明し，以降で様々なモデルを実装していくための基礎を獲得することを目的とします．\n","# 目次\n","\n","0.   準備\n","1.   テンソル生成方法\n","2.   種々の演算\n","3.   GPUの利用方法\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DgBaszmDrHBg","colab_type":"text"},"source":["## 準備\n","**ファイルの設定**　本稿は Google Colabolatory 上で実行されることを想定して作成されています．\n","以降でGPUを用いた演算を解説する際の準備として，はじめにファイルの設定を変更します．\n","\n","本稿を Google Colabolatory 上で開いたのち，上部メニューから「編集」→「ノートブックの設定」を選択し，ハードウェアアクセラレータをGPUに設定してください．この設定変更はそれまでに実行されていたランタイムを初期化するため，必ず最初に行うようにしてください．\n","\n","以降，GPUによる演算が必要なノートブックでは適宜同様の設定を行なってください．\n","\n","**PyTorchのインポート** Google Colabolatory ではPyTorchがあらかじめインストールされています．"]},{"cell_type":"code","metadata":{"id":"kowObAdrqbgT","colab_type":"code","colab":{}},"source":["import torch                   # PyTorchのインポート\n","print(torch.__version__)       # バージョン確認\n","print(torch.cuda.is_available()) # GPUが正しく利用できるかの確認\n","import numpy as np # numpyのインポート"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zJtzak4xxCcp","colab_type":"text"},"source":["## テンソルの生成方法\n","----\n","**サイズを指定したテンソル生成**\n","\n","任意サイズのテンソルを生成するために，単純に領域を確保することができます．値の初期化はなされません．\n","\n","以下では例としてベクトル・行列・高階テンソルの領域をそれぞれ確保しています．同様に，任意の自然数を列挙することで様々なサイズのテンソルを生成することができます．"]},{"cell_type":"code","metadata":{"id":"bHkvmXEwvfAm","colab_type":"code","colab":{}},"source":["# 1D vector\n","x = torch.empty(3)\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mjYW5kZGBddA","colab_type":"code","colab":{}},"source":["# 2D matrix\n","x = torch.empty(2, 3)\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQ8cDn2MBdNL","colab_type":"code","colab":{}},"source":["# 3D tensor\n","x = torch.empty(2, 3, 2)\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nTrmMzoC0mlh","colab_type":"text"},"source":["生成したテンソルのサイズは以下のように確認することができます．"]},{"cell_type":"code","metadata":{"id":"yt4ZEEZ60m6N","colab_type":"code","colab":{}},"source":["print(x.size())  # テンソルのサイズを取得\n","print(x.size(0)) # テンソルの0次元目のサイズを取得"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qcw8ueee94pl","colab_type":"text"},"source":["また，0や1などの特定の値や任意の値で埋めたテンソルを生成することができます．"]},{"cell_type":"code","metadata":{"id":"70bf7d8J-Cb9","colab_type":"code","colab":{}},"source":["# 0で埋める\n","x = torch.zeros(2, 2)\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-1Tj8WJKBvDC","colab_type":"code","colab":{}},"source":["# 1で埋める\n","x = torch.ones(2, 2)\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NUqHd2ZVBxTl","colab_type":"code","colab":{}},"source":["# 任意の値（ここでは3.1415）で埋める\n","x = torch.full((2, 2), 3.1415)\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gj8A_YHd_Ah6","colab_type":"text"},"source":["乱数によって初期化されたテンソルを生成することもできます．"]},{"cell_type":"code","metadata":{"id":"oDt4EAAO-O8r","colab_type":"code","colab":{}},"source":["# 標準正規分布で初期化\n","x = torch.randn(2, 2)\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QVMJKB5nB3UU","colab_type":"code","colab":{}},"source":["# 0~1の一様分布で初期化\n","x = torch.rand(2, 2)\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dMOLmeta_d3Z","colab_type":"text"},"source":["----\n","**リストやnumpy.ndarrayからの変換**\n","\n","あらかじめ定めた要素値によりテンソルを生成したい場合は，次のようにして実現できます．"]},{"cell_type":"code","metadata":{"id":"SgInInic_OTu","colab_type":"code","colab":{}},"source":["# リストから生成\n","x = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_vWNch-xC61n","colab_type":"text"},"source":["また，NumPy上でなんらかの計算を施した既存のndarrayをPyTorch上で利用したい場合も，同様のメソッドを用いることが可能です．このとき，ndarrayに設定されていた数値型がそのまま引き継がれます．\n","\n","なお，print文による表示桁数は丸められてしまいますが，各要素には確かに数値型に対応する精度の数値が格納されています．"]},{"cell_type":"code","metadata":{"id":"TNYRnWUfDbDH","colab_type":"code","colab":{}},"source":["# 既存のndarrayとして準備\n","a = np.random.randn(3, 2)\n","print(a)\n","print(a.dtype)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oJOvBSGKEsh_","colab_type":"code","colab":{}},"source":["# numpy.ndarrayから生成\n","x = torch.tensor(a)\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BBz9Uv8RTvNV","colab_type":"text"},"source":["----\n","**要素の取り出し**\n","リストやNumPyのndarrayと同様，スライスにより要素を取り出すことができます．"]},{"cell_type":"code","metadata":{"id":"rJNfTr2GEvkh","colab_type":"code","colab":{}},"source":["# 要素の取り出し\n","print(x[:2, :])\n","print(x[0, [1, 0]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pXi4hzshUB57","colab_type":"code","colab":{}},"source":["# 1要素のテンソルを単なるスカラー値に変換するために　item を用いることができる\n","print(x[0, 0].item())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UnqXTpxn_78g","colab_type":"text"},"source":["----\n","**数値型**\n","\n","PyTorchにもNumPyと同様に数値型の概念が存在します．数値型はテンソル生成時に指定できるほか，一度生成したテンソルを別の型に変換することもできます．\n","\n","指定しない場合は基本的にfloat型とみなされます．よく用いられる型はfloat型およびlong型です．"]},{"cell_type":"code","metadata":{"id":"aGsF6kNk_0MN","colab_type":"code","colab":{}},"source":["# dtypeを指定することによるfloat型での生成（numpy.float32に対応）\n","x = torch.ones(2, 2, dtype=torch.float)\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"45xXfGskEB4y","colab_type":"text"},"source":["既存のリストやnumpy.ndarrayを明示的にtorch.float型のテンソルへ変換することもできます．"]},{"cell_type":"code","metadata":{"id":"ceqtnWy4EKB1","colab_type":"code","colab":{}},"source":["# 先ほど用意した既存のndarray\n","print(a)\n","print(a.dtype)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Of8qtCn7F0BP","colab_type":"code","colab":{}},"source":["# numpy.ndarrayからtorch.floatのテンソルを生成\n","x = torch.FloatTensor(a)\n","print(x)\n","print(x.dtype)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FKpP0ozMAxp8","colab_type":"code","colab":{}},"source":["# dtypeを指定することによるlong型での生成（numpy.int64に対応）\n","x = torch.ones(2, 2, dtype=torch.long)\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BlY55O7bF5YC","colab_type":"text"},"source":["同様に，既存のリストやnumpy.ndarrayを明示的にtorch.long型のテンソルへ変換することができます．"]},{"cell_type":"code","metadata":{"id":"Qwu9eHwFGA2W","colab_type":"code","colab":{}},"source":["# numpy.ndarrayからtorch.longのテンソルを生成\n","x = torch.LongTensor(a)\n","print(x)\n","print(x.dtype)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rmZhZG08CDHH","colab_type":"code","colab":{}},"source":["# torch.floatからtorch.longへの変換\n","f = torch.randn(4, 4)\n","print(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s1WUzZdxIL91","colab_type":"code","colab":{}},"source":["l = f.long()\n","print(l)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Xg-Z1erCET3","colab_type":"code","colab":{}},"source":["# torch.longからtorch.floatへの変換\n","f2 = l.float()\n","print(f2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DM1fGA1UIuk2","colab_type":"text"},"source":["---\n","**既存のテンソルと同サイズのテンソル生成**\n","\n","様々なアルゴリズムを実装していくにあたり，同サイズのテンソルを複数用意して演算を行うという場面は頻出します．そこでPyTorchには，あるテンソルを基準に同サイズのテンソルを簡単に生成できるようにするための機能が備わっています．\n","\n","これにより，全てのテンソルに同じサイズを明示的に割り当てるコードを書く冗長性の排除や，テンソルサイズを可変にしてもコードの見通しが良くなるといった利点が生まれます．"]},{"cell_type":"code","metadata":{"id":"wfPF212ZCOU4","colab_type":"code","colab":{}},"source":["# 既存テンソル\n","x = torch.empty(2, 5, 2)\n","print(x.size())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kYbXBUpaKEwz","colab_type":"code","colab":{}},"source":["# xと同サイズの0埋めテンソルを生成\n","y = torch.zeros_like(x)\n","print(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wkdLP0OKMba","colab_type":"code","colab":{}},"source":["# xと同サイズの1埋めテンソルを生成\n","y = torch.ones_like(x)\n","print(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rVv0Qen2KQMW","colab_type":"code","colab":{}},"source":["# xと同サイズで任意の値で埋めたテンソルを生成\n","y = torch.full_like(x, 3.1415)\n","print(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QTNdTeApKWc_","colab_type":"code","colab":{}},"source":["# xと同サイズで標準正規分布で初期化されたテンソルを生成\n","y = torch.randn_like(x)\n","print(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Hc3bvL3KclU","colab_type":"code","colab":{}},"source":["# xと同サイズで0~1の一様分布で初期化されたテンソルを生成\n","y = torch.rand_like(x)\n","print(y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LGbfayJvQAzo","colab_type":"text"},"source":["## 種々の演算\n","----\n","**四則演算**　基礎的な四則演算をテンソル同士で行うことができます．"]},{"cell_type":"code","metadata":{"id":"zfcK-JbHQWhX","colab_type":"code","colab":{}},"source":["# テンソルの準備\n","x = torch.randn(1, 2)\n","y = torch.randn(1, 2)\n","print(x)\n","print(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AXCR4NEtKgiY","colab_type":"code","colab":{}},"source":["# 加算\n","z = x + y\n","print(z)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nsufpFSjQk0t","colab_type":"code","colab":{}},"source":["# 減算\n","z = x - y\n","print(z)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AoHHILGWQny0","colab_type":"code","colab":{}},"source":["# 要素ごとの乗算\n","z = x * y\n","print(z)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e4T5cmZTQqvt","colab_type":"code","colab":{}},"source":["# 要素ごとの除算\n","z = x / y\n","print(z)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XetEF1ROB4IW","colab_type":"code","colab":{}},"source":["# 冪乗\n","z = x**2\n","print(z)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dc3fBH_oDOU1","colab_type":"text"},"source":["---\n","**利用可能な数学関数** 様々な数学関数や集計関数が利用できます"]},{"cell_type":"code","metadata":{"id":"912DynDs4bkS","colab_type":"code","colab":{}},"source":["x = torch.randn(1,2)\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vNfGvMgDDrB3","colab_type":"code","colab":{}},"source":["# 要素ごとの絶対値\n","z = torch.abs(x)\n","print(z)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-JTLIog9D3-p","colab_type":"code","colab":{}},"source":["# 要素ごとに三角関数を適用\n","z = torch.sin(x)\n","print(z)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bsdix4uNEB4X","colab_type":"code","colab":{}},"source":["# 要素ごとに指数関数を適用\n","z = torch.exp(x)\n","print(z)\n","\n","# 要素ごとに対数関数を適用\n","z = torch.log(x)\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RWptHNzlEg97","colab_type":"code","colab":{}},"source":["# 合計\n","z = torch.sum(x)\n","print(z)\n","# 最大値\n","z = torch.max(x)\n","print(z)\n","# 平均\n","z = torch.mean(x)\n","print(z)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wbC_f-zsXn_A","colab_type":"text"},"source":["----\n","**テンソルサイズの変更**　\n","PyTorchのテンソルサイズはviewを用いて任意に整形できます．"]},{"cell_type":"code","metadata":{"id":"69p13XNAZ-C7","colab_type":"code","colab":{}},"source":["x = torch.randn(2, 3, 4)\n","print(x)\n","print(x.size())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SScPttVBaEMQ","colab_type":"code","colab":{}},"source":["y = x.view(6, 4)\n","print(y)\n","print(y.size())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c80ltBCzaJ9K","colab_type":"code","colab":{}},"source":["# -1を指定すると整合するように自動で整数を推定してくれる\n","y = x.view(1, 2, -1, 2, 2)\n","print(y)\n","print(y.size())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tKO2wlMzaQRl","colab_type":"text"},"source":["**軸の入れ替え**　テンソルにおける任意の2軸の順番を入れ替えることができます．"]},{"cell_type":"code","metadata":{"id":"JJ2uKmx_aW7g","colab_type":"code","colab":{}},"source":["y = x.transpose(2, 0)\n","print(y)\n","print(y.size())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"opQRlPyIbD6a","colab_type":"text"},"source":["2次元行列の場合は単純に転置することも可能です．"]},{"cell_type":"code","metadata":{"id":"6bReYdUIbJQb","colab_type":"code","colab":{}},"source":["m = torch.randn(3, 2)\n","print(m)\n","print(m.size())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7dll2iKObNEN","colab_type":"code","colab":{}},"source":["# 転置行列を返す\n","n = m.t()\n","print(n)\n","print(n.size())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"69o4ylzRbfVT","colab_type":"text"},"source":["全ての軸の順番を指定して入れ替えることも可能です．"]},{"cell_type":"code","metadata":{"id":"qBd1A9IRbqkp","colab_type":"code","colab":{}},"source":["# 軸の順列を指定して入れ替える\n","y = x.permute(2, 0, 1)\n","print(y)\n","print(y.size())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kF5e39UMb2Gq","colab_type":"text"},"source":["**メモリの整列**　上記にあげたテンソルの整形や軸の入れ替えは任意の操作数重ね合わせることが可能です．しかしながら，軸を入れ替えると表記上のテンソルと内部で確保されているメモリの並びが不整合となる場合があり，その後にviewメソッドを用いると失敗します．"]},{"cell_type":"code","metadata":{"id":"LwsVYwZ2cPTZ","colab_type":"code","colab":{}},"source":["# view size is not compatible with input tensor's size and stride... というエラーが生じる\n","# 今回はこの stride の部分に問題がある\n","z = x.transpose(2, 0).view(2, 2, 6)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZMy-TTS-cgjO","colab_type":"text"},"source":["このようなエラーが発生した場合は，一度メモリの並びを整列させる操作を噛ませることで解消可能です．"]},{"cell_type":"code","metadata":{"id":"uA33CcQ1cgHX","colab_type":"code","colab":{}},"source":["z = x.transpose(2, 0).contiguous().view(2, 2, 6)\n","print(z)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZuOCj42PWK7I","colab_type":"text"},"source":["----\n","**in-placeな演算**　\n","通常の演算では，出力テンソルとして新たなメモリ領域が確保されています．しかしながら，メモリの使用量を抑制したい場合等に，入力テンソルの要素をそのまま置換するように演算を行うことができます．\n","\n","*   加算：add_\n","*   減算：sub_\n","*   乗算：mul_\n","*   除算：div_\n","*   転置：t_\n","*   軸の入れ替え：transpose_\n","*   値のコピー：copy_\n","\n","等が用意されています．\n","\n"]},{"cell_type":"code","metadata":{"id":"DZelty_IQwQc","colab_type":"code","colab":{}},"source":["# テンソルの準備\n","x = torch.randn(1, 2)\n","y = torch.randn(1, 2)\n","print(x)\n","print(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5VXQOEZVWp8S","colab_type":"code","colab":{}},"source":["# xにyをin-placeに加算する\n","x.add_(y)\n","# x自体の値が演算結果で書き換わる\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"asGbBbkNWyCB","colab_type":"code","colab":{}},"source":["# xをin-placeに転置する\n","x.t_()\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wh3z60yzXVYq","colab_type":"code","colab":{}},"source":["# xの軸をin-placeに入れ替える\n","x.transpose_(0,1)\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iABtahP4c_k9","colab_type":"code","colab":{}},"source":["# xにyの値をコピーする\n","x.copy_(y)\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2L2zAYJAUShp","colab_type":"text"},"source":["ただし，後続のノートブックで説明する自動微分機能を用いる際は，基本的にin-placeな演算を行うことはできないことに留意してください．"]},{"cell_type":"markdown","metadata":{"id":"-N2eZQwbf4aK","colab_type":"text"},"source":["## GPUの利用方法\n","----\n","**生成済のテンソルをGPUメモリに載せる**ことができます．複数枚のGPUが搭載されたサーバ上で実行する場合はGPU番号を指定することが推奨されますが，Google Colaboratory は1枚のみの搭載のため以下のようにして簡単に既存テンソルをGPU上のテンソル（CUDA Tensor）に変換することができます．"]},{"cell_type":"code","metadata":{"id":"7qw06AmifnuN","colab_type":"code","colab":{}},"source":["x_cuda = x.cuda()\n","print(x_cuda)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t_XfXOTgg9uw","colab_type":"text"},"source":["テンソルの生成時にdeviceを指定することで，**初めからGPU上のメモリを確保してテンソルを生成する**ことも可能です．"]},{"cell_type":"code","metadata":{"id":"gvGUsFbBg476","colab_type":"code","colab":{}},"source":["x = torch.randn(1, 2, device=\"cuda:0\")\n","print(x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xz4JrdqShL8L","colab_type":"text"},"source":["存在しないGPU番号を指定するとエラーが発生します．"]},{"cell_type":"code","metadata":{"id":"UI5MUyOnhIhV","colab_type":"code","colab":{}},"source":["x = torch.randn(1, 2, device=\"cuda:1\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HzEZssbAhnnB","colab_type":"text"},"source":["同じデバイス上のテンソルを用いて，先に紹介したような演算を同様に行うことが可能です．\n","ただし，異なるデバイス同士（CPUとGPU，または異なる番号のGPU同士）での演算はできません．\n","\n","**CPUへの変換**　GPU上のテンソルは，同様に簡単にCPU上に移行することが可能です．"]},{"cell_type":"code","metadata":{"id":"ivZwMT6-hkPJ","colab_type":"code","colab":{}},"source":["# CPUへ\n","x_cpu = x_cuda.cpu()\n","print(x_cpu)\n","print(x_cpu.device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kUQdu6TwPNoz","colab_type":"text"},"source":["**統一的な記法**　PyTorchが扱うテンソルは，デバイス名を文字列で指定することで簡単にデバイス間を移動させることができます．"]},{"cell_type":"code","metadata":{"id":"gsH6AAVwPdly","colab_type":"code","colab":{}},"source":["# CPU上で生成\n","x = torch.randn(2, 2)\n","print(x.device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lQ2ijgFlPsn-","colab_type":"code","colab":{}},"source":["# 0番GPUへ\n","x_cuda0 = x.to(\"cuda:0\")\n","print(x_cuda0.device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WEDadbejP9Gl","colab_type":"code","colab":{}},"source":["# CPUへ\n","x_cpu = x_cuda0.to(\"cpu\")\n","print(x_cpu.device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NaVta6gPQErw","colab_type":"text"},"source":["さらに，既存のテンソルを引数として，同じデバイス・同じ数値型への変換を行うことも可能です．"]},{"cell_type":"code","metadata":{"id":"4Uhmkz3cQNDr","colab_type":"code","colab":{}},"source":["# 0番GPUにdouble型のテンソルを生成\n","d_cuda0 = torch.randn(2, 2, dtype=torch.double, device=\"cuda:0\")\n","print(d_cuda0.device)\n","print(d_cuda0.dtype)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v50HAb5RQkBp","colab_type":"code","colab":{}},"source":["# xをd_cuda0と同じデバイス・数値型へ変換する\n","x_d = x.to(d_cuda0)\n","print(x_d.device)\n","print(x_d.dtype)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eE1vaARZikTO","colab_type":"text"},"source":["**他の配列オブジェクトへの変換**　CPU上のテンソルに限り，numpy.ndarrayやリストなどへ変換することができます．"]},{"cell_type":"code","metadata":{"id":"rE6mf3FwitO4","colab_type":"code","colab":{}},"source":["# numpy.ndarrayに変換\n","x_ndarray = x_cpu.numpy()\n","print(x_ndarray)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kTmoeGVki30A","colab_type":"code","colab":{}},"source":["# リストに変換\n","x_list = x_cpu.tolist()\n","print(x_list)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p4o4KZ_znXFQ","colab_type":"text"},"source":["# 課題\n","<h4>\n","平均二乗誤差関数の実装\n","</h4>\n","\n"," \n","入力：$\\boldsymbol{X}=(\\boldsymbol{x}_1,\\boldsymbol{x}_2,\\cdots\\boldsymbol{x}_{N})^{T}\\in\\mathbb{R}^{N\\times M},　\\boldsymbol{Y}=(\\boldsymbol{y}_1,\\boldsymbol{y}_2,\\cdots\\boldsymbol{y}_{N})^{T}\\in\\mathbb{R}^{N\\times M}$\n","      \n","出力：$z\\in\\mathbb{R}, z=L(\\boldsymbol{X}, \\boldsymbol{Y}~)$\n","    \n","    \n","\n","- 平均二乗誤差 :\n","$$ \n","L(\\boldsymbol{X},\\boldsymbol{Y}~) = \\frac{1}{N}\\sum^N_i \\|\\boldsymbol{x}_i-\\boldsymbol{y}_i\\|_2^2\\\\\n","$$\n","Numpyのndarrayを受け取り，GPU上で平均二乗誤差を計算して，GPU上のメモリに乗ったテンソルを出力する関数を実装してみましょう\n"]},{"cell_type":"code","metadata":{"id":"PFWqps8NsO6K","colab_type":"code","colab":{}},"source":["def MSE(x, y):\n","  # TODO\n","  \n","  return z"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mScj3R0c965I","colab_type":"code","colab":{}},"source":["from google.colab import drive # driveを接続\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5pKJ9oq--SdT","colab_type":"code","colab":{}},"source":["# drive中の課題ファイルのあるディレクトリに移動\n","%cd /content/gdrive/My Drive/FAI20200602/data\n","from test import *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oqtAzquusb8e","colab_type":"code","colab":{}},"source":["test_MSE(MSE)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bEcerwNzsk-N","colab_type":"text"},"source":["OKと出力されれば完成です"]},{"cell_type":"markdown","metadata":{"id":"DN_K12HWiGru","colab_type":"text"},"source":["最終項で紹介したGPU上での演算は極めて重要であり，今日では専らGPUを用いて演算することが主流となっています．\n","というのも，一般の配列操作や行列演算等はGPUを用いることで高速に並列計算可能なためです．このような装置の恩恵もあって今日の深層学習モデルは現実的な時間で学習させることが可能となっています．\n","\n","----\n","お疲れ様でした．本稿は以上で終了いたします．\n","以降のハンズオンでは、深層学習において重要な概念のひとつである自動微分機能について解説したのち，具体的なデータセットとタスクを通してより深層学習モデルに関する知見を深めていきます．"]}]}