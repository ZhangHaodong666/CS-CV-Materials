{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"転移学習とFine Tuning.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4v8gSEW6vkUH"},"source":["# **転移学習**\n","本章では転移学習と呼ばれる手法を紹介し，訓練済みのモデルを元にして，手元にある少量のデータを用いた画像分類モデルを構築する手法を示します．それに伴い，PyTorchが提供している主要な学習済みモデルのロード方法と，構築した自作モデルの保存と読み出しについても解説します．"]},{"cell_type":"markdown","metadata":{"id":"jUKVw4sRtF-A","colab_type":"text"},"source":["## 転移学習とは\n","前章まででは，CIFAR-10の60,000枚の画像を使って10種類のクラス分類の画像認識モデルを構築し訓練を行いました．しかし実応用上は，自分がクラス分類を行いたいドメインの画像に対して，十分な量のデータセットを用意できるケースは稀でしょう．\n","\n","一般にVGGやResNetといったImageNetなどの大規模画像データセットを使用して訓練を行った画像認識モデルでは，入力に近い層は画像のより抽象的な部分を，出力に近い層はドメインのより具体的な特徴にフォーカスした部分を見ていると言われており，このうち前者に関しては異なるドメインの画像に対しても有効な特徴抽出器として機能すると期待できます．そこで，学習済みモデルの最終出力層を自前のデータに対応した出力層に付け替え，付け替えた出力層への結合パラメータを手元にある少量のデータで訓練し直すことを考えます．このような手法を**転移学習（Transfer Learning）**と呼びます．\n","\n","また，転移学習では入力層に近い部分の結合パラメータは訓練済みの値から変化させませんが，これらに関しても手元のデータを用いて訓練し直す場合の手法は**Fine Tuning**と呼びます．これに関しては後半で解説します．\n","\n","本節では，VGG-16の訓練済みモデルをベースに，PyTorchの公式Tutorialで使用されているアリとハチの画像を分類するモデルを訓練します．"]},{"cell_type":"markdown","metadata":{"id":"ralQoPK31SL9","colab_type":"text"},"source":["## 準備\n","以降を読み進めるにあたって，予め以下のパッケージをimportしておいてください．"]},{"cell_type":"code","metadata":{"id":"NaB7y-1j2HNC","colab_type":"code","colab":{}},"source":["# from https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n","# License: BSD\n","# Author: Sasank Chilamkurthy\n","\n","from __future__ import print_function, division\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","\n","plt.ion()   # interactive mode\n","\n","# random seed\n","import random\n","torch.manual_seed(1234)\n","np.random.seed(1234)\n","random.seed(1234)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xhh46KiVQkl1","colab_type":"text"},"source":["本章はCNNの訓練を行うので，CPUでの計算だとそれなりに時間がかかってしまいます．そこで，GPUを使用することで訓練を高速化しましょう．上のツールバーのRuntimeからChange runtime typeを選択して， Hardware acceleratorをGPUに設定します．また，PyTorchでのTensorの計算をGPUデバイス上で行うため，次のコードを実行してください．"]},{"cell_type":"code","metadata":{"id":"1mj2DF5nQt0c","colab_type":"code","colab":{}},"source":["# GPUの使用\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4sQV-ZBC2f-P","colab_type":"text"},"source":["## データセットの作成\n","実験に使用するアリ🐜とハチ🐝の画像データセットを作成します．これらはそれぞれおよそ120枚の訓練データと75枚の検証データから成ります．これらはスクラッチからモデルを訓練するには非常に小さいデータセットですが，転移学習を用いることで性能の良いDNNモデルを実現することができます．\n","\n","まずは，drive中にある画像ファイルの入ったzipファイルを解凍し，使用するデータのパスを読み込みましょう．"]},{"cell_type":"code","metadata":{"id":"GJWWvd904Abd","colab_type":"code","colab":{}},"source":["from google.colab import drive # driveを接続\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dz6PbeZ07EZt","colab_type":"code","colab":{}},"source":["# drive中の課題ファイルのあるディレクトリに移動\n","%cd /content/gdrive/My Drive/FAI20200602/data/transfer_learning\n","# zipファイルを解凍\n","!unzip hymenoptera_data.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fqnRcn948hWk","colab_type":"code","colab":{}},"source":["data_dir = '/content/gdrive/My Drive/FAI20200602/data/transfer_learning/hymenoptera_data'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qa1FrLWj9hLy","colab_type":"text"},"source":["データセットは`torchvision.datasets.ImageFolder`クラスを利用して簡単に作成することができます．これを使って例えば以下のような画像がクラスごとに別々のディレクトリに格納されているディレクトリを指定すると，各ディレクトリ名をラベルとして自動でラベル付けを行ったDatasetオブジェクトを生成することができます．\n","\n","        root/dog/xxx.png\n","        root/dog/xxy.png\n","        root/dog/xxz.png\n","\n","        root/cat/123.png\n","        root/cat/nsdf3.png\n","        root/cat/asd932_.png\n","\n","また，この際予め画像に施しておくべき前処理をtorchvision.`transforms.data_transforms`クラスのオブジェクトを引数とすることで指定できます．今回は．訓練時と検証時で異なる前処理を行っており，訓練時の前処理には`RandomResizedCrop`と`RandomHorizontalFlip`をかませることでデータ拡張を実施しています．"]},{"cell_type":"code","metadata":{"id":"Cl0xvSHt2Tm3","colab_type":"code","colab":{}},"source":["# 訓練時に使う画像にはデータ拡張と正規化を実施\n","# 検証時に使う画像に対しては正規化のみを実施\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","# trainディレクトリとvalディレクトリそれぞれの中にある画像を使って訓練時と検証時それぞれのデータセットを作る\n","# さらにそれぞれantsとbeesディレクトリに分かれており，これらのラベルが振られる\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n","                                          data_transforms[x])\n","                  for x in ['train', 'val']}\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n","                                             shuffle=True, num_workers=4)\n","              for x in ['train', 'val']}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","class_names = image_datasets['train'].classes"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v5x3WPys_feb","colab_type":"text"},"source":["訓練画像を可視化してどんな画像が含まれているのかチェックしておきましょう．"]},{"cell_type":"code","metadata":{"id":"h6wabvi884tR","colab_type":"code","colab":{}},"source":["def imshow(inp, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","\n","\n","# 訓練データをバッチごとに取り出す\n","# 詳しくは「画像分類機を訓練する」ノートブックのサンプルコードのコメントを見てください\n","inputs, classes = next(iter(dataloaders['train']))\n","\n","# torchvision.utils.make_gridでバッチでまとまった複数の画像を，タイル状に並べた1枚の画像を表すTensorにできる\n","out = torchvision.utils.make_grid(inputs[0:4])\n","\n","imshow(out, title=[class_names[x] for x in classes[0:4]])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HihMxL-CugeP","colab_type":"text"},"source":["## 学習済みモデルのロード\n","PyTorchでは，VGGやResNetなどいくつかの有名なモデルに関しては学習済みの状態でロードできるようになっています．本節では学習済みのVGG−16モデルをロードし使用することにしましょう．"]},{"cell_type":"code","metadata":{"id":"QZTHS-Ub85RA","colab_type":"code","colab":{}},"source":["# 訓練済みのVGG-16モデルをロード\n","use_pretrained = True # 訓練済みのパラメータを使用する\n","model = models.vgg16(pretrained=use_pretrained)\n","\n","# 訓練モードに設定\n","model.train()\n","print(model)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cQ7WyTluBE-D","colab_type":"text"},"source":["ここで，一番最後の(classifier)(6):Linearに注目すると，出力ユニットの数が1000となっており，VGG-16を訓練するのに用いたImageNetデータセットが1000種類のクラス分類用データセットであることがわかります．今回はアリとハチの2種類の画像を分類したいので，このclassifierモジュールの最後にある全結合層を付け替えることにしましょう．"]},{"cell_type":"code","metadata":{"id":"cTtwoGkuAw88","colab_type":"code","colab":{}},"source":["model.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n","# GPUデバイスにモデルを移動\n","model = model.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"97t--q4ZC7bp","colab_type":"text"},"source":["## 損失関数・最適化手法の設定\n","ネットワークモデルの作成が完了したので，続いて損失関数を定義しましょう．今回の画像分類タスクは通常のクラス分類ですので，クロスエントロピー誤差を使用することにします．"]},{"cell_type":"code","metadata":{"id":"naTdvgqVB48x","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3833xX4bDY_P","colab_type":"text"},"source":["続いて最適化手法の設定ですが，今回の転移学習ではclassifierの最終層（付け替えた部分）のみを訓練したいので，それ以外の層では誤差逆伝播による勾配計算によってパラメータが更新されないように設定する必要があります．固定したいパラメータ`param`に対して`param.requires_grad=False`とすることでこれを行います．"]},{"cell_type":"code","metadata":{"id":"YqyD4YAQDYGH","colab_type":"code","colab":{}},"source":["params_to_update = []\n","\n","update_param_names = [\"classifier.6.weight\", \"classifier.6.bias\"]\n","\n","# named_parameters()でnn.Moduleクラスオブジェクトの各層の重みパラメータを重みの名前（linear.weight, linear.biasなど）付きで取得できる\n","for name, param in model.named_parameters():\n","    if name in update_param_names:\n","        param.requires_grad = True\n","        params_to_update.append(param)\n","    else:\n","        param.requires_grad = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JOqCQCl0Ffq_","colab_type":"text"},"source":["この上で，`params_to_update`だけを`optimizer`に渡します．"]},{"cell_type":"code","metadata":{"id":"wk8KjE14FRSQ","colab_type":"code","colab":{}},"source":["optimizer = optim.SGD(params=params_to_update, lr=0.001, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wTOphuJ43lua","colab_type":"text"},"source":["## 訓練の実行\n","ここまでの設定を用いて訓練を行います．"]},{"cell_type":"code","metadata":{"id":"Bpv5Wvl7FWU7","colab_type":"code","colab":{}},"source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n","        print('-' * 10)\n","\n","        # それぞれのエポックには訓練フェイズと検証フェイズがある\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # モデルを訓練モードに\n","            else:\n","                model.eval()  # モデルを検証モードに\n","\n","            running_loss = 0.0  # 各バッチでのロスの累積和\n","            running_corrects = 0  # 各バッチでの正解数の累積和\n","\n","            # 未学習時の検証性能を確かめるため，epoch=0の訓練はskip\n","            if (epoch == 0) and (phase == \"train\"):\n","                continue\n","\n","            # dataloaderからバッチをとりだす\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device) \n","                labels = labels.to(device)\n","\n","                # 各層の勾配をゼロに初期化\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # 訓練時のみ勾配計算を行う\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)  # 各バッチでのロスを累積\n","                running_corrects += torch.sum(preds == labels.data)  # 各バッチでの正解数を累積\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]  # エポック全体でのロスの平均\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]  # エポック全体での正解率\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","\n","            # 検証フェイズでもっとも正解率が高かったときの正解率とモデルの重みパラメータを保存\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # もっとも正解率が高かったときのモデルを返す\n","    model.load_state_dict(best_model_wts)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gr5fijaQFjYV","colab_type":"code","colab":{}},"source":["train_model(model, dataloaders, criterion, optimizer, num_epochs=25)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GP2lcUDRNrnx","colab_type":"text"},"source":["訓練中に各epochでの訓練データと検証データそれぞれでのaccuracyを計算していますが，最初のepochでは未学習時（訓練済みのVGGモデルをそのまま用いた場合）のaccuracyを計算していることに注意してください．未学習の状態ではおおよそ50%程度のaccuracyであると思います．しかし訓練を続けていくとすぐにaccuracyは90%を超え，最終的には訓練データと検証データともに95%前後のaccuracyを得ることができました．入力に近い層で既に画像の一般的な特徴を捉えることはできているので，あとは出力に近い層を手元の訓練データに特化して調整し直すとそれなりに高い性能のモデルを得ることができる，ということがわかりました．"]},{"cell_type":"markdown","metadata":{"id":"APcDaanxPMUl","colab_type":"text"},"source":["# Fine Tuning\n","前節までで扱った転移学習では出力層や出力層に近い部分以外のパラメータは固定しましたが，これらも含めて全層のパラメータを再学習させる手法は**Fine Tuning**と呼ばれます．ただし，Fine Tuningでは入力層に近い部分のパラメータは学習率を小さくし，出力層に近い部分のパラメータは学習率を大きく設定するのが一般的です．これは，入力に近い部分は特徴抽出器としてそれなりに仕上がっていることが期待されるので，あとは手元のデータセットによりフィットするように小さい学習率で微調整を図る，という考えによります．\n","\n","またこの2つの手法を組み合わせることも可能です．つまり，訓練済みのモデルに対して，はじめは出力層以外は固定した状態で訓練を行い（転移学習），その後それらの固定を解除して全層での訓練を行う（Fine Tuning），という2段階のステップを踏むということです．そこで今回は，前節で訓練したVGGモデルをさらにFine Tuningで微調整していく，という実験に取り組むことにします．"]},{"cell_type":"markdown","metadata":{"id":"GBcynuNGJQuZ","colab_type":"text"},"source":["基本的には転移学習でのコードをそのまま使い回せますが，出力層以外の層のパラメータに関しても勾配が計算されるように`requires_grad=True`にしておきます．また層ごとに学習率を変えたいので，学習率によって層をグループ分けしておきます．"]},{"cell_type":"code","metadata":{"id":"AX7slUtUdbg3","colab_type":"code","colab":{}},"source":["# 設定する学習率によって層を3つにグループ分けする\n","params_to_update_1 = []\n","params_to_update_2 = []\n","params_to_update_3 = []\n","\n","update_param_names_1 = [\"features\"]\n","update_param_names_2 = [\"classifier.0.weight\", \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\n","update_param_names_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n","\n","for name, param in model.named_parameters():\n","  if update_param_names_1[0] in name:\n","    param.requires_grad = True\n","    params_to_update_1.append(param)\n","  \n","  elif name in update_param_names_2:\n","    param.requires_grad = True\n","    params_to_update_2.append(param)\n","\n","  elif name in update_param_names_3:\n","    param.requires_grad = True\n","    params_to_update_3.append(param) \n","  \n","  else:\n","    param.requires_grad = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ITARZVkLKZBJ","colab_type":"text"},"source":["それではこれらの勾配を計算したいパラメータをoptimizerに渡してあげましょう．"]},{"cell_type":"code","metadata":{"id":"-4fDvUG_e7dk","colab_type":"code","colab":{}},"source":["optimizer_ft = optim.SGD([\n","                       {'params': params_to_update_1, 'lr': 1e-4},\n","                       {'params': params_to_update_2, 'lr': 5e-4},\n","                       {'params': params_to_update_3, 'lr': 1e-3},\n","], momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iynIH3sLKtuS","colab_type":"text"},"source":["訓練を行います．"]},{"cell_type":"code","metadata":{"id":"mRKynk6bfbUr","colab_type":"code","colab":{}},"source":["train_model(model, dataloaders, criterion, optimizer_ft, num_epochs=25)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"InZtYaY5gZaS","colab_type":"text"},"source":["# モデルの保存と読み出し\n","最後に，訓練したモデルを保存する方法を紹介します． PyTorchではモデルそのものを保存することは推奨されておらず，訓練したパラメータを辞書型変数として保存する方法が一般的です． 具体的には，ネットワークモデル変数`model`に対して，`model.state_dict()`でパラメータを辞書型変数として取り出し，`torch.save()`で保存します．"]},{"cell_type":"code","metadata":{"id":"GpRYfAyMPK4W","colab_type":"code","colab":{}},"source":["model_path = './params/model.pth'\n","torch.save(model.state_dict(), model_path)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jY8QxvrjjCHX","colab_type":"text"},"source":["保存したパラメータを読み出すには，`torch.load()`で辞書型オブジェクトを読み出し，保存時と同じ構造をもつネットワークモデル変数`model`に対して，`model.load_state_dict()`で呼び出したパラメータを格納します．"]},{"cell_type":"code","metadata":{"id":"mAnJ4GCvFrAw","colab_type":"code","colab":{}},"source":["model_path = './params/model.pth'\n","model.load_state_dict(torch.load(model_path))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_4t6wjwekQvH","colab_type":"text"},"source":["ただし，GPUで学習したモデルをCPUで読み込みたい場合は注意が必要です．ナイーブな方法は，保存時に予め`model.to('cpu')`でモデルをcpuに移した上で保存しておくことでしょう．"]},{"cell_type":"code","metadata":{"id":"oKA-9T5PJHCj","colab_type":"code","colab":{}},"source":["model_path = './params/model.pth'\n","torch.save(model.to('cpu').state_dict(), model_path)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n7WIK2B0k4sb","colab_type":"text"},"source":["しかし，場合によっては自分ではなく他人がGPUモデルとして保存したパラメータをCPU上で読み出したい場合もあります．その場合には，`map_location`を使用することで対応することができます．"]},{"cell_type":"code","metadata":{"id":"NO9V4wNKlJJK","colab_type":"code","colab":{}},"source":["model_path = './params/model.pth'\n","model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1z3noVrZekcg","colab_type":"text"},"source":["# 参考文献\n","[1] [TRANSFER LEARNING FOR COMPUTER VISION TUTORIAL](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html) \n","\n","[2] 「つくりながら学ぶ！PyTorchによる発展ディープラーニング」 小川雄太郎、マイナビ出版"]}]}